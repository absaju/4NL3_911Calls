{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports to run Baselines\n",
    "# pip install nltk pandas numpy scikit-learn\n",
    "# Python 3.9\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once\n",
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processing Code\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def rem_punc(text):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "def rem_stopwords(list):\n",
    "    stop_words = stopwords.words('english')\n",
    "    return [word for word in list if word not in stop_words]\n",
    "\n",
    "def lem(list):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in list]\n",
    "\n",
    "def stem(list):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(word) for word in list]\n",
    "\n",
    "def preprocessing(text, stemy=False):\n",
    "    text = lower(text)\n",
    "    text = rem_punc(text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    list = text.split()\n",
    "    list = lem(list)\n",
    "    if stemy: list = stem(list)\n",
    "    list = rem_stopwords(list)\n",
    "    return \" \".join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5333\n",
      "\n",
      "Classification Report BOW Logical Regression:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Fire_Department       0.75      0.50      0.60         6\n",
      "Law_Enforcement       0.79      0.55      0.65        42\n",
      "  Non_Emergency       0.21      1.00      0.34         7\n",
      "     Paramedics       0.88      0.35      0.50        20\n",
      "\n",
      "       accuracy                           0.53        75\n",
      "      macro avg       0.66      0.60      0.52        75\n",
      "   weighted avg       0.76      0.53      0.58        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logical Regression Baseline-Model\n",
    "train_data = pd.read_csv(\"training_data.csv\")\n",
    "validation_data = pd.read_csv(\"validation_data.csv\")\n",
    "\n",
    "y_train = train_data['labels'].values\n",
    "train_corpus = []\n",
    "for i in range(0, len(train_data['labels'])):\n",
    "    train_corpus.append(preprocessing(train_data['file_content'][i]))\n",
    "\n",
    "y_test = validation_data['labels'].values\n",
    "test_corpus = []\n",
    "for i in range(0, len(validation_data['labels'])):\n",
    "    test_corpus.append(preprocessing(validation_data['file_content'][i]))\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x_train = cv.fit_transform(train_corpus).toarray()\n",
    "x_test = cv.transform(test_corpus).toarray()\n",
    "\n",
    "classifier = LogisticRegression(max_iter=500)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "''' If you want to see the failing cases\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == y_pred[i]:\n",
    "        correct += 1\n",
    "        total += 1\n",
    "        print(\"Passed ----> \", end=\"\")\n",
    "    else:\n",
    "        total += 1\n",
    "        print(\"Failed ----> \", end=\"\")\n",
    "    print(\"actual: \" + y_test[i] + \", prediction: \" + y_pred[i])\n",
    "'''\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report BOW Logical Regression:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Baseline Accuracy: 0.5600\n",
      "\n",
      "Report\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Fire_Department       0.00      0.00      0.00         6\n",
      "Law_Enforcement       0.56      1.00      0.72        42\n",
      "  Non_Emergency       0.00      0.00      0.00         7\n",
      "     Paramedics       0.00      0.00      0.00        20\n",
      "\n",
      "       accuracy                           0.56        75\n",
      "      macro avg       0.14      0.25      0.18        75\n",
      "   weighted avg       0.31      0.56      0.40        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Majority-Baseline Model\n",
    "most_common_label = max(set(y_train), key=list(y_train).count)\n",
    "majority_prediction = np.array([most_common_label] * len(y_test))\n",
    "\n",
    "\n",
    "majority_baseline = accuracy_score(y_test, majority_prediction)\n",
    "print(f\"Majority Baseline Accuracy: {majority_baseline:.4f}\")\n",
    "print(\"\\nReport\")\n",
    "print(classification_report(y_test, majority_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.csv format\n",
    "testing_data = pd.read_csv(\"testing_data.csv\")\n",
    "test_corpus = []\n",
    "for i in range(0, len(testing_data['id'])):\n",
    "    test_corpus.append(preprocessing(testing_data['file_content'][i]))\n",
    "x_testing = cv.transform(test_corpus).toarray()\n",
    "\n",
    "\n",
    "testing_predictions = classifier.predict(x_testing)\n",
    "testing_data['labels'] = testing_predictions\n",
    "testing_data.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# This is the format of submission expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
